# END3.0-Session11
Sunny Manchanda

SESSION 11 - BERT and BART
ASSIGNMENT

TASK 1 (Week 1): Train BERT using the code mentioned here https://drive.google.com/file/d/1Zp2_Uka8oGDYsSe5ELk-xz6wIX8OIkB7/view?usp=sharing on the Squad Dataset for 20% overall samples (1/5 Epochs).
Show results on 5 samples.
TASK 2 (Week 1): Reproductive these https://mccormickml.com/2019/07/22/BERT-fine-tuning/ results.
Show output on 5 samples.
TASK 3 (Week 2): Reproduce the training explained in this blog https://towardsdatascience.com/bart-for-paraphrasing-with-simple-transformers-7c9ea3dfdd8c.
You can decide to pick fewer datasets.
Proceed to Session 11 - Assignment Solutions page and:
Submit README link for Task 1 (training log snippets and 5 sample results along with BERT description must be available) - 750
Submit README link for Task 2 (training log snippets and 5 sample results) - 250
Submit README link for Task 3 (training log snippets and 5 sample results along with BART description must be available) - 1000
